{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "log_dir = './logs/ML_Lab_10-01-Softmax'\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 784] , name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, nb_classes], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('softmax') as scope:\n",
    "    W = tf.Variable(tf.random_normal(shape=[784, nb_classes]), shape=[784, nb_classes], dtype=tf.float32, name='weight')\n",
    "    b = tf.Variable(tf.random_normal(shape=[nb_classes]), shape=[nb_classes], dtype=tf.float32, name='bias')\n",
    "    logits = tf.matmul(X, W) + b\n",
    "    hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "    tf.summary.histogram(\"W\", W)\n",
    "    tf.summary.histogram(\"b\", b)\n",
    "    tf.summary.histogram(\"softmax\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('cost') as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Train') as scope:\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-154051bf3954>:2: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('accuracy') as scope:\n",
    "    is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 5.745171013\n",
      "Accuracy:  0.5672\n",
      "Epoch: 0002 cost = 1.780056718\n",
      "Accuracy:  0.7327\n",
      "Epoch: 0003 cost = 1.122778639\n",
      "Accuracy:  0.7984\n",
      "Epoch: 0004 cost = 0.872012252\n",
      "Accuracy:  0.8304\n",
      "Epoch: 0005 cost = 0.738203181\n",
      "Accuracy:  0.8531\n",
      "Epoch: 0006 cost = 0.654728886\n",
      "Accuracy:  0.8674\n",
      "Epoch: 0007 cost = 0.596023610\n",
      "Accuracy:  0.8769\n",
      "Epoch: 0008 cost = 0.552216819\n",
      "Accuracy:  0.8827\n",
      "Epoch: 0009 cost = 0.518254963\n",
      "Accuracy:  0.8879\n",
      "Epoch: 0010 cost = 0.491113199\n",
      "Accuracy:  0.8901\n",
      "Epoch: 0011 cost = 0.468347538\n",
      "Accuracy:  0.8936\n",
      "Epoch: 0012 cost = 0.449374352\n",
      "Accuracy:  0.8987\n",
      "Epoch: 0013 cost = 0.432675664\n",
      "Accuracy:  0.8979\n",
      "Epoch: 0014 cost = 0.418828155\n",
      "Accuracy:  0.9023\n",
      "Epoch: 0015 cost = 0.406128932\n",
      "Accuracy:  0.9023\n",
      "Epoch: 0016 cost = 0.394982938\n",
      "Accuracy:  0.9051\n",
      "Epoch: 0017 cost = 0.385870417\n",
      "Accuracy:  0.9057\n",
      "Epoch: 0018 cost = 0.376135583\n",
      "Accuracy:  0.9082\n",
      "Epoch: 0019 cost = 0.368269375\n",
      "Accuracy:  0.9095\n",
      "Epoch: 0020 cost = 0.361209771\n",
      "Accuracy:  0.9089\n",
      "Epoch: 0021 cost = 0.354798137\n",
      "Accuracy:  0.9098\n",
      "Epoch: 0022 cost = 0.348525122\n",
      "Accuracy:  0.9091\n",
      "Epoch: 0023 cost = 0.342752723\n",
      "Accuracy:  0.9116\n",
      "Epoch: 0024 cost = 0.337285907\n",
      "Accuracy:  0.9108\n",
      "Epoch: 0025 cost = 0.332443592\n",
      "Accuracy:  0.9124\n",
      "Epoch: 0026 cost = 0.327556528\n",
      "Accuracy:  0.9122\n",
      "Epoch: 0027 cost = 0.324047224\n",
      "Accuracy:  0.9147\n",
      "Epoch: 0028 cost = 0.319670893\n",
      "Accuracy:  0.9128\n",
      "Epoch: 0029 cost = 0.315536201\n",
      "Accuracy:  0.9147\n",
      "Epoch: 0030 cost = 0.312257757\n",
      "Accuracy:  0.9152\n",
      "Epoch: 0031 cost = 0.308550809\n",
      "Accuracy:  0.9154\n",
      "Epoch: 0032 cost = 0.305987608\n",
      "Accuracy:  0.9164\n",
      "Epoch: 0033 cost = 0.302624452\n",
      "Accuracy:  0.9158\n",
      "Epoch: 0034 cost = 0.299895891\n",
      "Accuracy:  0.9168\n",
      "Epoch: 0035 cost = 0.297245870\n",
      "Accuracy:  0.9177\n",
      "Epoch: 0036 cost = 0.294490161\n",
      "Accuracy:  0.9173\n",
      "Epoch: 0037 cost = 0.292061206\n",
      "Accuracy:  0.9158\n",
      "Epoch: 0038 cost = 0.290009238\n",
      "Accuracy:  0.9167\n",
      "Epoch: 0039 cost = 0.287633523\n",
      "Accuracy:  0.9193\n",
      "Epoch: 0040 cost = 0.285644491\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0041 cost = 0.283856596\n",
      "Accuracy:  0.9162\n",
      "Epoch: 0042 cost = 0.281824813\n",
      "Accuracy:  0.9194\n",
      "Epoch: 0043 cost = 0.280098964\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0044 cost = 0.278386733\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0045 cost = 0.276589553\n",
      "Accuracy:  0.9177\n",
      "Epoch: 0046 cost = 0.275093698\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0047 cost = 0.273444047\n",
      "Accuracy:  0.92\n",
      "Epoch: 0048 cost = 0.271918681\n",
      "Accuracy:  0.9207\n",
      "Epoch: 0049 cost = 0.270640432\n",
      "Accuracy:  0.9205\n",
      "Epoch: 0050 cost = 0.269054373\n",
      "Accuracy:  0.9194\n",
      "Epoch: 0051 cost = 0.267672022\n",
      "Accuracy:  0.919\n",
      "Epoch: 0052 cost = 0.266659588\n",
      "Accuracy:  0.9201\n",
      "Epoch: 0053 cost = 0.265153419\n",
      "Accuracy:  0.9211\n",
      "Epoch: 0054 cost = 0.264101975\n",
      "Accuracy:  0.921\n",
      "Epoch: 0055 cost = 0.263282135\n",
      "Accuracy:  0.9206\n",
      "Epoch: 0056 cost = 0.261912937\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0057 cost = 0.260929373\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0058 cost = 0.259908021\n",
      "Accuracy:  0.92\n",
      "Epoch: 0059 cost = 0.258959316\n",
      "Accuracy:  0.922\n",
      "Epoch: 0060 cost = 0.258065545\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0061 cost = 0.256745012\n",
      "Accuracy:  0.921\n",
      "Epoch: 0062 cost = 0.255830209\n",
      "Accuracy:  0.9219\n",
      "Epoch: 0063 cost = 0.255352689\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0064 cost = 0.254253003\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0065 cost = 0.253390754\n",
      "Accuracy:  0.9231\n",
      "Epoch: 0066 cost = 0.253018637\n",
      "Accuracy:  0.9222\n",
      "Epoch: 0067 cost = 0.251986480\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0068 cost = 0.251307343\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0069 cost = 0.250830279\n",
      "Accuracy:  0.9211\n",
      "Epoch: 0070 cost = 0.249936236\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0071 cost = 0.249179044\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0072 cost = 0.248447971\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0073 cost = 0.248001494\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0074 cost = 0.247446171\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0075 cost = 0.246376248\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0076 cost = 0.245950562\n",
      "Accuracy:  0.9219\n",
      "Epoch: 0077 cost = 0.245185416\n",
      "Accuracy:  0.9237\n",
      "Epoch: 0078 cost = 0.245071632\n",
      "Accuracy:  0.9231\n",
      "Epoch: 0079 cost = 0.244021832\n",
      "Accuracy:  0.9234\n",
      "Epoch: 0080 cost = 0.243740821\n",
      "Accuracy:  0.9232\n",
      "Epoch: 0081 cost = 0.242865351\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0082 cost = 0.242756650\n",
      "Accuracy:  0.9227\n",
      "Epoch: 0083 cost = 0.242286091\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0084 cost = 0.241499498\n",
      "Accuracy:  0.9234\n",
      "Epoch: 0085 cost = 0.241308772\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0086 cost = 0.240599259\n",
      "Accuracy:  0.9209\n",
      "Epoch: 0087 cost = 0.240379510\n",
      "Accuracy:  0.9229\n",
      "Epoch: 0088 cost = 0.239959786\n",
      "Accuracy:  0.922\n",
      "Epoch: 0089 cost = 0.239449682\n",
      "Accuracy:  0.9218\n",
      "Epoch: 0090 cost = 0.238913359\n",
      "Accuracy:  0.9233\n",
      "Epoch: 0091 cost = 0.238484520\n",
      "Accuracy:  0.9236\n",
      "Epoch: 0092 cost = 0.237802814\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0093 cost = 0.237509683\n",
      "Accuracy:  0.9218\n",
      "Epoch: 0094 cost = 0.237025084\n",
      "Accuracy:  0.924\n",
      "Epoch: 0095 cost = 0.237164269\n",
      "Accuracy:  0.9222\n",
      "Epoch: 0096 cost = 0.236957810\n",
      "Accuracy:  0.9236\n",
      "Epoch: 0097 cost = 0.236461367\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0098 cost = 0.235961379\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0099 cost = 0.235605157\n",
      "Accuracy:  0.9243\n",
      "Epoch: 0100 cost = 0.235282743\n",
      "Accuracy:  0.9246\n",
      "Label: [8]\n",
      "[[1.8915973e-07 3.9835825e-08 1.2392789e-04 6.0978037e-04 2.2865927e-03\n",
      "  3.0019393e-03 9.1904724e-07 4.4313419e-06 9.9347609e-01 4.9615378e-04]]\n",
      "Prediction: [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/Deep_NN\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(log_dir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, train], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch        \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "        # Test he model using test sets\n",
    "        print('Accuracy: ', accuracy.eval(session=sess, feed_dict={X:mnist.test.images, Y: mnist.test.labels}))\n",
    "        \n",
    "        summary = sess.run(merged_summary, feed_dict={X:mnist.test.images, Y: mnist.test.labels})\n",
    "        writer.add_summary(summary, global_step=(epoch))\n",
    "        #print('Accuracy: ', sess.run(accuracy, feed_dict={X:mnist.test.images, Y: mnist.test.labels}))\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples -1)\n",
    "   \n",
    "    print('Label:', sess.run(tf.arg_max(mnist.test.labels[r:r+1], 1)))\n",
    "    print(sess.run(hypothesis, feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "    print('Prediction:', sess.run(tf.arg_max(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
