{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "log_dir = './logs/ML_Lab_10-01-Softmax'\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 784] , name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, nb_classes], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('softmax') as scope:\n",
    "    W = tf.Variable(tf.random_normal(shape=[784, nb_classes]), shape=[784, nb_classes], dtype=tf.float32, name='weight')\n",
    "    b = tf.Variable(tf.random_normal(shape=[nb_classes]), shape=[nb_classes], dtype=tf.float32, name='bias')\n",
    "    logits = tf.matmul(X, W) + b\n",
    "    hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "    tf.summary.histogram(\"W\", W)\n",
    "    tf.summary.histogram(\"b\", b)\n",
    "    tf.summary.histogram(\"softmax\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('cost') as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Train') as scope:\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-154051bf3954>:2: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('accuracy') as scope:\n",
    "    is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 5.745171013\n",
      "Accuracy:  0.5672\n",
      "Epoch: 0002 cost = 1.780056718\n",
      "Accuracy:  0.7327\n",
      "Epoch: 0003 cost = 1.122778639\n",
      "Accuracy:  0.7984\n",
      "Epoch: 0004 cost = 0.872012252\n",
      "Accuracy:  0.8304\n",
      "Epoch: 0005 cost = 0.738203181\n",
      "Accuracy:  0.8531\n",
      "Epoch: 0006 cost = 0.654728886\n",
      "Accuracy:  0.8674\n",
      "Epoch: 0007 cost = 0.596023610\n",
      "Accuracy:  0.8769\n",
      "Epoch: 0008 cost = 0.552216819\n",
      "Accuracy:  0.8827\n",
      "Epoch: 0009 cost = 0.518254963\n",
      "Accuracy:  0.8879\n",
      "Epoch: 0010 cost = 0.491113199\n",
      "Accuracy:  0.8901\n",
      "Epoch: 0011 cost = 0.468347538\n",
      "Accuracy:  0.8936\n",
      "Epoch: 0012 cost = 0.449374352\n",
      "Accuracy:  0.8987\n",
      "Epoch: 0013 cost = 0.432675664\n",
      "Accuracy:  0.8979\n",
      "Epoch: 0014 cost = 0.418828155\n",
      "Accuracy:  0.9023\n",
      "Epoch: 0015 cost = 0.406128932\n",
      "Accuracy:  0.9023\n",
      "Epoch: 0016 cost = 0.394982938\n",
      "Accuracy:  0.9051\n",
      "Epoch: 0017 cost = 0.385870417\n",
      "Accuracy:  0.9057\n",
      "Epoch: 0018 cost = 0.376135583\n",
      "Accuracy:  0.9082\n",
      "Epoch: 0019 cost = 0.368269375\n",
      "Accuracy:  0.9095\n",
      "Epoch: 0020 cost = 0.361209771\n",
      "Accuracy:  0.9089\n",
      "Epoch: 0021 cost = 0.354798137\n",
      "Accuracy:  0.9098\n",
      "Epoch: 0022 cost = 0.348525122\n",
      "Accuracy:  0.9091\n",
      "Epoch: 0023 cost = 0.342752723\n",
      "Accuracy:  0.9116\n",
      "Epoch: 0024 cost = 0.337285907\n",
      "Accuracy:  0.9108\n",
      "Epoch: 0025 cost = 0.332443592\n",
      "Accuracy:  0.9124\n",
      "Epoch: 0026 cost = 0.327556528\n",
      "Accuracy:  0.9122\n",
      "Epoch: 0027 cost = 0.324047224\n",
      "Accuracy:  0.9147\n",
      "Epoch: 0028 cost = 0.319670893\n",
      "Accuracy:  0.9128\n",
      "Epoch: 0029 cost = 0.315536201\n",
      "Accuracy:  0.9147\n",
      "Epoch: 0030 cost = 0.312257757\n",
      "Accuracy:  0.9152\n",
      "Epoch: 0031 cost = 0.308550809\n",
      "Accuracy:  0.9154\n",
      "Epoch: 0032 cost = 0.305987608\n",
      "Accuracy:  0.9164\n",
      "Epoch: 0033 cost = 0.302624452\n",
      "Accuracy:  0.9158\n",
      "Epoch: 0034 cost = 0.299895891\n",
      "Accuracy:  0.9168\n",
      "Epoch: 0035 cost = 0.297245870\n",
      "Accuracy:  0.9177\n",
      "Epoch: 0036 cost = 0.294490161\n",
      "Accuracy:  0.9173\n",
      "Epoch: 0037 cost = 0.292061206\n",
      "Accuracy:  0.9158\n",
      "Epoch: 0038 cost = 0.290009238\n",
      "Accuracy:  0.9167\n",
      "Epoch: 0039 cost = 0.287633523\n",
      "Accuracy:  0.9193\n",
      "Epoch: 0040 cost = 0.285644491\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0041 cost = 0.283856596\n",
      "Accuracy:  0.9162\n",
      "Epoch: 0042 cost = 0.281824813\n",
      "Accuracy:  0.9194\n",
      "Epoch: 0043 cost = 0.280098964\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0044 cost = 0.278386733\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0045 cost = 0.276589553\n",
      "Accuracy:  0.9177\n",
      "Epoch: 0046 cost = 0.275093698\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0047 cost = 0.273444047\n",
      "Accuracy:  0.92\n",
      "Epoch: 0048 cost = 0.271918681\n",
      "Accuracy:  0.9207\n",
      "Epoch: 0049 cost = 0.270640432\n",
      "Accuracy:  0.9205\n",
      "Epoch: 0050 cost = 0.269054373\n",
      "Accuracy:  0.9194\n",
      "Epoch: 0051 cost = 0.267672022\n",
      "Accuracy:  0.919\n",
      "Epoch: 0052 cost = 0.266659588\n",
      "Accuracy:  0.9201\n",
      "Epoch: 0053 cost = 0.265153419\n",
      "Accuracy:  0.9211\n",
      "Epoch: 0054 cost = 0.264101975\n",
      "Accuracy:  0.921\n",
      "Epoch: 0055 cost = 0.263282135\n",
      "Accuracy:  0.9206\n",
      "Epoch: 0056 cost = 0.261912937\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0057 cost = 0.260929373\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0058 cost = 0.259908021\n",
      "Accuracy:  0.92\n",
      "Epoch: 0059 cost = 0.258959316\n",
      "Accuracy:  0.922\n",
      "Epoch: 0060 cost = 0.258065545\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0061 cost = 0.256745012\n",
      "Accuracy:  0.921\n",
      "Epoch: 0062 cost = 0.255830209\n",
      "Accuracy:  0.9219\n",
      "Epoch: 0063 cost = 0.255352689\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0064 cost = 0.254253003\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0065 cost = 0.253390754\n",
      "Accuracy:  0.9231\n",
      "Epoch: 0066 cost = 0.253018637\n",
      "Accuracy:  0.9222\n",
      "Epoch: 0067 cost = 0.251986480\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0068 cost = 0.251307343\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0069 cost = 0.250830279\n",
      "Accuracy:  0.9211\n",
      "Epoch: 0070 cost = 0.249936236\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0071 cost = 0.249179044\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0072 cost = 0.248447971\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0073 cost = 0.248001494\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0074 cost = 0.247446171\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0075 cost = 0.246376248\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0076 cost = 0.245950562\n",
      "Accuracy:  0.9219\n",
      "Epoch: 0077 cost = 0.245185416\n",
      "Accuracy:  0.9237\n",
      "Epoch: 0078 cost = 0.245071632\n",
      "Accuracy:  0.9231\n",
      "Epoch: 0079 cost = 0.244021832\n",
      "Accuracy:  0.9234\n",
      "Epoch: 0080 cost = 0.243740821\n",
      "Accuracy:  0.9232\n",
      "Epoch: 0081 cost = 0.242865351\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0082 cost = 0.242756650\n",
      "Accuracy:  0.9227\n",
      "Epoch: 0083 cost = 0.242286091\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0084 cost = 0.241499498\n",
      "Accuracy:  0.9234\n",
      "Epoch: 0085 cost = 0.241308772\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0086 cost = 0.240599259\n",
      "Accuracy:  0.9209\n",
      "Epoch: 0087 cost = 0.240379510\n",
      "Accuracy:  0.9229\n",
      "Epoch: 0088 cost = 0.239959786\n",
      "Accuracy:  0.922\n",
      "Epoch: 0089 cost = 0.239449682\n",
      "Accuracy:  0.9218\n",
      "Epoch: 0090 cost = 0.238913359\n",
      "Accuracy:  0.9233\n",
      "Epoch: 0091 cost = 0.238484520\n",
      "Accuracy:  0.9236\n",
      "Epoch: 0092 cost = 0.237802814\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0093 cost = 0.237509683\n",
      "Accuracy:  0.9218\n",
      "Epoch: 0094 cost = 0.237025084\n",
      "Accuracy:  0.924\n",
      "Epoch: 0095 cost = 0.237164269\n",
      "Accuracy:  0.9222\n",
      "Epoch: 0096 cost = 0.236957810\n",
      "Accuracy:  0.9236\n",
      "Epoch: 0097 cost = 0.236461367\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0098 cost = 0.235961379\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0099 cost = 0.235605157\n",
      "Accuracy:  0.9243\n",
      "Epoch: 0100 cost = 0.235282743\n",
      "Accuracy:  0.9246\n",
      "Label: [3]\n",
      "[[1.6571954e-08 5.2496133e-04 1.2515101e-02 8.9822549e-01 6.2622062e-06\n",
      "  1.2836832e-02 3.1234291e-07 5.3153373e-05 7.1431242e-02 4.4067018e-03]]\n",
      "Prediction: [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/Deep_NN\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(log_dir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, train], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch        \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "        # Test he model using test sets\n",
    "        print('Accuracy: ', accuracy.eval(session=sess, feed_dict={X:mnist.test.images, Y: mnist.test.labels}))\n",
    "        \n",
    "        summary = sess.run(merged_summary, feed_dict={X:mnist.test.images, Y: mnist.test.labels})\n",
    "        writer.add_summary(summary, global_step=(epoch))\n",
    "        #print('Accuracy: ', sess.run(accuracy, feed_dict={X:mnist.test.images, Y: mnist.test.labels}))\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples -1)\n",
    "   \n",
    "    print('Label:', sess.run(tf.arg_max(mnist.test.labels[r:r+1], 1)))\n",
    "    print(sess.run(hypothesis, feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "    print('Prediction:', sess.run(tf.arg_max(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
