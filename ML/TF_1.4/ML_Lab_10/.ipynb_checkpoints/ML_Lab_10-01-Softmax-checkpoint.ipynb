{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "log_dir = './logs/ML_Lab_10-01-Softmax'\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 784] , name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, nb_classes], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('softmax') as scope:\n",
    "    W = tf.Variable(tf.random_normal(shape=[784, nb_classes]), shape=[784, nb_classes], dtype=tf.float32, name='weight')\n",
    "    b = tf.Variable(tf.random_normal(shape=[nb_classes]), shape=[nb_classes], dtype=tf.float32, name='bias')\n",
    "    logits = tf.matmul(X, W) + b\n",
    "    hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "    tf.summary.histogram(\"W\", W)\n",
    "    tf.summary.histogram(\"b\", b)\n",
    "    tf.summary.histogram(\"softmax\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('cost') as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Train') as scope:\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-154051bf3954>:2: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('accuracy') as scope:\n",
    "    is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 5.745171013\n",
      "Accuracy:  0.5672\n",
      "Epoch: 0002 cost = 1.780056718\n",
      "Accuracy:  0.7327\n",
      "Epoch: 0003 cost = 1.122778639\n",
      "Accuracy:  0.7984\n",
      "Epoch: 0004 cost = 0.872012252\n",
      "Accuracy:  0.8304\n",
      "Epoch: 0005 cost = 0.738203181\n",
      "Accuracy:  0.8531\n",
      "Epoch: 0006 cost = 0.654728886\n",
      "Accuracy:  0.8674\n",
      "Epoch: 0007 cost = 0.596023610\n",
      "Accuracy:  0.8769\n",
      "Epoch: 0008 cost = 0.552216819\n",
      "Accuracy:  0.8827\n",
      "Epoch: 0009 cost = 0.518254963\n",
      "Accuracy:  0.8879\n",
      "Epoch: 0010 cost = 0.491113199\n",
      "Accuracy:  0.8901\n",
      "Epoch: 0011 cost = 0.468347538\n",
      "Accuracy:  0.8936\n",
      "Epoch: 0012 cost = 0.449374352\n",
      "Accuracy:  0.8987\n",
      "Epoch: 0013 cost = 0.432675664\n",
      "Accuracy:  0.8979\n",
      "Epoch: 0014 cost = 0.418828155\n",
      "Accuracy:  0.9023\n",
      "Epoch: 0015 cost = 0.406128932\n",
      "Accuracy:  0.9023\n",
      "Epoch: 0016 cost = 0.394982938\n",
      "Accuracy:  0.9051\n",
      "Epoch: 0017 cost = 0.385870417\n",
      "Accuracy:  0.9057\n",
      "Epoch: 0018 cost = 0.376135583\n",
      "Accuracy:  0.9082\n",
      "Epoch: 0019 cost = 0.368269375\n",
      "Accuracy:  0.9095\n",
      "Epoch: 0020 cost = 0.361209771\n",
      "Accuracy:  0.9089\n",
      "Epoch: 0021 cost = 0.354798137\n",
      "Accuracy:  0.9098\n",
      "Epoch: 0022 cost = 0.348525122\n",
      "Accuracy:  0.9091\n",
      "Epoch: 0023 cost = 0.342752723\n",
      "Accuracy:  0.9116\n",
      "Epoch: 0024 cost = 0.337285907\n",
      "Accuracy:  0.9108\n",
      "Epoch: 0025 cost = 0.332443592\n",
      "Accuracy:  0.9124\n",
      "Epoch: 0026 cost = 0.327556528\n",
      "Accuracy:  0.9122\n",
      "Epoch: 0027 cost = 0.324047224\n",
      "Accuracy:  0.9147\n",
      "Epoch: 0028 cost = 0.319670893\n",
      "Accuracy:  0.9128\n",
      "Epoch: 0029 cost = 0.315536201\n",
      "Accuracy:  0.9147\n",
      "Epoch: 0030 cost = 0.312257757\n",
      "Accuracy:  0.9152\n",
      "Epoch: 0031 cost = 0.308550809\n",
      "Accuracy:  0.9154\n",
      "Epoch: 0032 cost = 0.305987608\n",
      "Accuracy:  0.9164\n",
      "Epoch: 0033 cost = 0.302624452\n",
      "Accuracy:  0.9158\n",
      "Epoch: 0034 cost = 0.299895891\n",
      "Accuracy:  0.9168\n",
      "Epoch: 0035 cost = 0.297245870\n",
      "Accuracy:  0.9177\n",
      "Epoch: 0036 cost = 0.294490161\n",
      "Accuracy:  0.9173\n",
      "Epoch: 0037 cost = 0.292061206\n",
      "Accuracy:  0.9158\n",
      "Epoch: 0038 cost = 0.290009238\n",
      "Accuracy:  0.9167\n",
      "Epoch: 0039 cost = 0.287633523\n",
      "Accuracy:  0.9193\n",
      "Epoch: 0040 cost = 0.285644491\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0041 cost = 0.283856596\n",
      "Accuracy:  0.9162\n",
      "Epoch: 0042 cost = 0.281824813\n",
      "Accuracy:  0.9194\n",
      "Epoch: 0043 cost = 0.280098964\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0044 cost = 0.278386733\n",
      "Accuracy:  0.9188\n",
      "Epoch: 0045 cost = 0.276589553\n",
      "Accuracy:  0.9177\n",
      "Epoch: 0046 cost = 0.275093698\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0047 cost = 0.273444047\n",
      "Accuracy:  0.92\n",
      "Epoch: 0048 cost = 0.271918681\n",
      "Accuracy:  0.9207\n",
      "Epoch: 0049 cost = 0.270640432\n",
      "Accuracy:  0.9205\n",
      "Epoch: 0050 cost = 0.269054373\n",
      "Accuracy:  0.9194\n",
      "Epoch: 0051 cost = 0.267672022\n",
      "Accuracy:  0.919\n",
      "Epoch: 0052 cost = 0.266659588\n",
      "Accuracy:  0.9201\n",
      "Epoch: 0053 cost = 0.265153419\n",
      "Accuracy:  0.9211\n",
      "Epoch: 0054 cost = 0.264101975\n",
      "Accuracy:  0.921\n",
      "Epoch: 0055 cost = 0.263282135\n",
      "Accuracy:  0.9206\n",
      "Epoch: 0056 cost = 0.261912937\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0057 cost = 0.260929373\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0058 cost = 0.259908021\n",
      "Accuracy:  0.92\n",
      "Epoch: 0059 cost = 0.258959316\n",
      "Accuracy:  0.922\n",
      "Epoch: 0060 cost = 0.258065545\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0061 cost = 0.256745012\n",
      "Accuracy:  0.921\n",
      "Epoch: 0062 cost = 0.255830209\n",
      "Accuracy:  0.9219\n",
      "Epoch: 0063 cost = 0.255352689\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0064 cost = 0.254253003\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0065 cost = 0.253390754\n",
      "Accuracy:  0.9231\n",
      "Epoch: 0066 cost = 0.253018637\n",
      "Accuracy:  0.9222\n",
      "Epoch: 0067 cost = 0.251986480\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0068 cost = 0.251307343\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0069 cost = 0.250830279\n",
      "Accuracy:  0.9211\n",
      "Epoch: 0070 cost = 0.249936236\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0071 cost = 0.249179044\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0072 cost = 0.248447971\n",
      "Accuracy:  0.9208\n",
      "Epoch: 0073 cost = 0.248001494\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0074 cost = 0.247446171\n",
      "Accuracy:  0.9216\n",
      "Epoch: 0075 cost = 0.246376248\n",
      "Accuracy:  0.9226\n",
      "Epoch: 0076 cost = 0.245950562\n",
      "Accuracy:  0.9219\n",
      "Epoch: 0077 cost = 0.245185416\n",
      "Accuracy:  0.9237\n",
      "Epoch: 0078 cost = 0.245071632\n",
      "Accuracy:  0.9231\n",
      "Epoch: 0079 cost = 0.244021832\n",
      "Accuracy:  0.9234\n",
      "Epoch: 0080 cost = 0.243740821\n",
      "Accuracy:  0.9232\n",
      "Epoch: 0081 cost = 0.242865351\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0082 cost = 0.242756650\n",
      "Accuracy:  0.9227\n",
      "Epoch: 0083 cost = 0.242286091\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0084 cost = 0.241499498\n",
      "Accuracy:  0.9234\n",
      "Epoch: 0085 cost = 0.241308772\n",
      "Accuracy:  0.9215\n",
      "Epoch: 0086 cost = 0.240599259\n",
      "Accuracy:  0.9209\n",
      "Epoch: 0087 cost = 0.240379510\n",
      "Accuracy:  0.9229\n",
      "Epoch: 0088 cost = 0.239959786\n",
      "Accuracy:  0.922\n",
      "Epoch: 0089 cost = 0.239449682\n",
      "Accuracy:  0.9218\n",
      "Epoch: 0090 cost = 0.238913359\n",
      "Accuracy:  0.9233\n",
      "Epoch: 0091 cost = 0.238484520\n",
      "Accuracy:  0.9236\n",
      "Epoch: 0092 cost = 0.237802814\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0093 cost = 0.237509683\n",
      "Accuracy:  0.9218\n",
      "Epoch: 0094 cost = 0.237025084\n",
      "Accuracy:  0.924\n",
      "Epoch: 0095 cost = 0.237164269\n",
      "Accuracy:  0.9222\n",
      "Epoch: 0096 cost = 0.236957810\n",
      "Accuracy:  0.9236\n",
      "Epoch: 0097 cost = 0.236461367\n",
      "Accuracy:  0.9228\n",
      "Epoch: 0098 cost = 0.235961379\n",
      "Accuracy:  0.9225\n",
      "Epoch: 0099 cost = 0.235605157\n",
      "Accuracy:  0.9243\n",
      "Epoch: 0100 cost = 0.235282743\n",
      "Accuracy:  0.9246\n",
      "Label: [5]\n",
      "[[3.3450057e-08 1.3477245e-06 4.3663505e-05 4.8078687e-04 1.1250107e-08\n",
      "  9.9784958e-01 8.7630260e-06 8.8284168e-18 1.6157671e-03 8.0096747e-13]]\n",
      "Prediction: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/Deep_NN\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(log_dir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, train], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch        \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "        # Test he model using test sets\n",
    "        print('Accuracy: ', accuracy.eval(session=sess, feed_dict={X:mnist.test.images, Y: mnist.test.labels}))\n",
    "        \n",
    "        summary = sess.run(merged_summary, feed_dict={X:mnist.test.images, Y: mnist.test.labels})\n",
    "        writer.add_summary(summary, global_step=(epoch))\n",
    "        #print('Accuracy: ', sess.run(accuracy, feed_dict={X:mnist.test.images, Y: mnist.test.labels}))\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples -1)\n",
    "   \n",
    "    print('Label:', sess.run(tf.arg_max(mnist.test.labels[r:r+1], 1)))\n",
    "    print(sess.run(hypothesis, feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "    print('Prediction:', sess.run(tf.arg_max(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
